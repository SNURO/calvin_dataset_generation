_target_: pytorch_lightning.callbacks.ModelCheckpoint
save_top_k: 1
verbose: True
monitor: eval_lh/avg_seq_len
mode: max
dirpath: saved_models
filename: '{epoch:02d}_{eval_lh/avg_seq_len:.2f}' #put back in when PL fixes this _{val/accuracy:.4f}'
every_n_epochs: ${callbacks.rollout_lh.rollout_freq}
